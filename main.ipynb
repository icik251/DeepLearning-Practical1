{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "source": [
    "## Load dataset and create dataloaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 channels (rbg), where each row contains 32x32 colour image for the current colour\n",
    "#next(iter(test_loader))[0][0].shape"
   ]
  },
  {
   "source": [
    "## Network architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BatchNorm2d\n",
    "from torch import nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, dropout_rate, activation_function_type):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        if activation_function_type == \"relu\":\n",
    "            activation_function = nn.ReLU()\n",
    "        elif activation_function_type == \"sigmoid\":\n",
    "            activation_function = nn.Sigmoid()\n",
    "        elif activation_function_type == \"leaky_relu\":\n",
    "            activation_function = nn.LeakyReLU()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # 3 is the rbg\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_function,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_function,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_function,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.drop_out = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 128, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "Training 27 variations of the network with different parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 0.413 |  Test Loss: 0.672 | Train acc: 85.358 | Test acc: 78.24 | Time taken: 0:00:17.517927\n",
      "Epoch: 30 | Train Loss: 0.403 |  Test Loss: 0.756 | Train acc: 85.58 | Test acc: 75.8 | Time taken: 0:00:15.771782\n",
      "Epoch: 31 | Train Loss: 0.398 |  Test Loss: 0.746 | Train acc: 85.96 | Test acc: 75.58 | Time taken: 0:00:14.537924\n",
      "Epoch: 32 | Train Loss: 0.38 |  Test Loss: 0.626 | Train acc: 86.478 | Test acc: 79.08 | Time taken: 0:00:14.682833\n",
      "Epoch: 33 | Train Loss: 0.368 |  Test Loss: 0.675 | Train acc: 86.96 | Test acc: 77.59 | Time taken: 0:00:14.494446\n",
      "Epoch: 34 | Train Loss: 0.367 |  Test Loss: 0.668 | Train acc: 86.974 | Test acc: 78.03 | Time taken: 0:00:14.438212\n",
      "Epoch: 35 | Train Loss: 0.357 |  Test Loss: 0.725 | Train acc: 87.22 | Test acc: 76.17 | Time taken: 0:00:14.429940\n",
      "Epoch: 36 | Train Loss: 0.362 |  Test Loss: 0.704 | Train acc: 86.91 | Test acc: 78.08 | Time taken: 0:00:14.393190\n",
      "Epoch: 37 | Train Loss: 0.342 |  Test Loss: 0.633 | Train acc: 87.754 | Test acc: 79.91 | Time taken: 0:00:14.666717\n",
      "Epoch: 38 | Train Loss: 0.337 |  Test Loss: 0.659 | Train acc: 87.932 | Test acc: 78.88 | Time taken: 0:00:14.826668\n",
      "Epoch: 39 | Train Loss: 0.327 |  Test Loss: 0.704 | Train acc: 88.328 | Test acc: 78.27 | Time taken: 0:00:14.197520\n",
      "Epoch: 40 | Train Loss: 0.32 |  Test Loss: 0.797 | Train acc: 88.504 | Test acc: 76.77 | Time taken: 0:00:14.402175\n",
      "Epoch: 41 | Train Loss: 0.319 |  Test Loss: 0.645 | Train acc: 88.556 | Test acc: 79.5 | Time taken: 0:00:14.378248\n",
      "Epoch: 42 | Train Loss: 0.304 |  Test Loss: 0.751 | Train acc: 89.142 | Test acc: 76.81 | Time taken: 0:00:14.285545\n",
      "Epoch: 43 | Train Loss: 0.309 |  Test Loss: 0.806 | Train acc: 88.874 | Test acc: 76.4 | Time taken: 0:00:14.263538\n",
      "Epoch: 44 | Train Loss: 0.295 |  Test Loss: 0.687 | Train acc: 89.416 | Test acc: 78.41 | Time taken: 0:00:14.299266\n",
      "Epoch: 45 | Train Loss: 0.279 |  Test Loss: 0.802 | Train acc: 89.97 | Test acc: 76.99 | Time taken: 0:00:14.317716\n",
      "Epoch: 46 | Train Loss: 0.285 |  Test Loss: 0.679 | Train acc: 89.656 | Test acc: 79.27 | Time taken: 0:00:14.327802\n",
      "Epoch: 47 | Train Loss: 0.271 |  Test Loss: 0.754 | Train acc: 90.262 | Test acc: 77.65 | Time taken: 0:00:14.297467\n",
      "Epoch: 48 | Train Loss: 0.258 |  Test Loss: 0.754 | Train acc: 90.74 | Test acc: 78.03 | Time taken: 0:00:14.418605\n",
      "Epoch: 49 | Train Loss: 0.252 |  Test Loss: 0.729 | Train acc: 90.884 | Test acc: 78.7 | Time taken: 0:00:14.440690\n",
      "Epoch: 50 | Train Loss: 0.244 |  Test Loss: 0.783 | Train acc: 91.376 | Test acc: 77.01 | Time taken: 0:00:14.330496\n",
      "Epoch: 51 | Train Loss: 0.247 |  Test Loss: 0.726 | Train acc: 91.064 | Test acc: 79.52 | Time taken: 0:00:14.284036\n",
      "Epoch: 52 | Train Loss: 0.243 |  Test Loss: 0.771 | Train acc: 91.312 | Test acc: 78.33 | Time taken: 0:00:14.209637\n",
      "Epoch: 53 | Train Loss: 0.238 |  Test Loss: 0.694 | Train acc: 91.458 | Test acc: 79.53 | Time taken: 0:00:14.327406\n",
      "Epoch: 54 | Train Loss: 0.235 |  Test Loss: 0.699 | Train acc: 91.49 | Test acc: 79.4 | Time taken: 0:00:14.272092\n",
      "Epoch: 55 | Train Loss: 0.23 |  Test Loss: 0.694 | Train acc: 91.6 | Test acc: 80.05 | Time taken: 0:00:14.295197\n",
      "Epoch: 56 | Train Loss: 0.222 |  Test Loss: 0.762 | Train acc: 91.9 | Test acc: 78.64 | Time taken: 0:00:14.260186\n",
      "Epoch: 57 | Train Loss: 0.222 |  Test Loss: 0.68 | Train acc: 91.864 | Test acc: 80.21 | Time taken: 0:00:14.301510\n",
      "Epoch: 58 | Train Loss: 0.21 |  Test Loss: 0.77 | Train acc: 92.478 | Test acc: 77.89 | Time taken: 0:00:14.276040\n",
      "Epoch: 59 | Train Loss: 0.208 |  Test Loss: 0.72 | Train acc: 92.484 | Test acc: 78.67 | Time taken: 0:00:14.151719\n",
      "Epoch: 60 | Train Loss: 0.204 |  Test Loss: 0.849 | Train acc: 92.636 | Test acc: 77.69 | Time taken: 0:00:14.321885\n",
      "Epoch: 61 | Train Loss: 0.202 |  Test Loss: 0.794 | Train acc: 92.674 | Test acc: 77.83 | Time taken: 0:00:14.352850\n",
      "Epoch: 62 | Train Loss: 0.191 |  Test Loss: 0.766 | Train acc: 93.086 | Test acc: 78.52 | Time taken: 0:00:14.135443\n",
      "Epoch: 63 | Train Loss: 0.193 |  Test Loss: 0.699 | Train acc: 93.014 | Test acc: 79.94 | Time taken: 0:00:14.334862\n",
      "Epoch: 64 | Train Loss: 0.188 |  Test Loss: 0.825 | Train acc: 93.296 | Test acc: 78.54 | Time taken: 0:00:14.443022\n",
      "Epoch: 65 | Train Loss: 0.182 |  Test Loss: 0.787 | Train acc: 93.386 | Test acc: 78.74 | Time taken: 0:00:14.346450\n",
      "Epoch: 66 | Train Loss: 0.192 |  Test Loss: 0.8 | Train acc: 93.086 | Test acc: 78.19 | Time taken: 0:00:14.211806\n",
      "Epoch: 67 | Train Loss: 0.171 |  Test Loss: 0.751 | Train acc: 93.736 | Test acc: 79.38 | Time taken: 0:00:14.297952\n",
      "Epoch: 68 | Train Loss: 0.164 |  Test Loss: 0.788 | Train acc: 94.07 | Test acc: 79.44 | Time taken: 0:00:14.282914\n",
      "Epoch: 69 | Train Loss: 0.169 |  Test Loss: 0.749 | Train acc: 93.824 | Test acc: 79.92 | Time taken: 0:00:14.176433\n",
      "Epoch: 70 | Train Loss: 0.166 |  Test Loss: 0.772 | Train acc: 94.034 | Test acc: 79.38 | Time taken: 0:00:14.379781\n",
      "Epoch: 71 | Train Loss: 0.167 |  Test Loss: 0.722 | Train acc: 94.036 | Test acc: 80.88 | Time taken: 0:00:14.289071\n",
      "Epoch: 72 | Train Loss: 0.156 |  Test Loss: 0.813 | Train acc: 94.3 | Test acc: 79.1 | Time taken: 0:00:14.201978\n",
      "Epoch: 73 | Train Loss: 0.156 |  Test Loss: 0.814 | Train acc: 94.458 | Test acc: 79.31 | Time taken: 0:00:14.260310\n",
      "Epoch: 74 | Train Loss: 0.171 |  Test Loss: 0.736 | Train acc: 93.83 | Test acc: 80.32 | Time taken: 0:00:14.210953\n",
      "Epoch: 75 | Train Loss: 0.148 |  Test Loss: 0.742 | Train acc: 94.726 | Test acc: 80.36 | Time taken: 0:00:14.138401\n",
      "Epoch: 76 | Train Loss: 0.148 |  Test Loss: 0.794 | Train acc: 94.67 | Test acc: 79.73 | Time taken: 0:00:14.208326\n",
      "Epoch: 77 | Train Loss: 0.152 |  Test Loss: 0.79 | Train acc: 94.506 | Test acc: 79.27 | Time taken: 0:00:14.134711\n",
      "Epoch: 78 | Train Loss: 0.144 |  Test Loss: 0.815 | Train acc: 94.84 | Test acc: 79.39 | Time taken: 0:00:14.286473\n",
      "Epoch: 79 | Train Loss: 0.149 |  Test Loss: 0.866 | Train acc: 94.64 | Test acc: 77.69 | Time taken: 0:00:14.217704\n",
      "Epoch: 80 | Train Loss: 0.144 |  Test Loss: 0.994 | Train acc: 94.758 | Test acc: 75.83 | Time taken: 0:00:14.143074\n",
      "Epoch: 81 | Train Loss: 0.136 |  Test Loss: 0.855 | Train acc: 95.21 | Test acc: 79.42 | Time taken: 0:00:14.149198\n",
      "Epoch: 82 | Train Loss: 0.13 |  Test Loss: 0.792 | Train acc: 95.388 | Test acc: 79.74 | Time taken: 0:00:14.264053\n",
      "Epoch: 83 | Train Loss: 0.138 |  Test Loss: 0.865 | Train acc: 94.974 | Test acc: 78.22 | Time taken: 0:00:14.312252\n",
      "Epoch: 84 | Train Loss: 0.139 |  Test Loss: 0.829 | Train acc: 95.018 | Test acc: 79.68 | Time taken: 0:00:14.455186\n",
      "Epoch: 85 | Train Loss: 0.127 |  Test Loss: 0.797 | Train acc: 95.432 | Test acc: 79.37 | Time taken: 0:00:14.361056\n",
      "Epoch: 86 | Train Loss: 0.123 |  Test Loss: 0.82 | Train acc: 95.568 | Test acc: 78.68 | Time taken: 0:00:14.271988\n",
      "Epoch: 87 | Train Loss: 0.129 |  Test Loss: 0.806 | Train acc: 95.328 | Test acc: 80.23 | Time taken: 0:00:14.289361\n",
      "Epoch: 88 | Train Loss: 0.12 |  Test Loss: 0.83 | Train acc: 95.636 | Test acc: 79.56 | Time taken: 0:00:14.269102\n",
      "Epoch: 89 | Train Loss: 0.117 |  Test Loss: 0.764 | Train acc: 95.898 | Test acc: 80.84 | Time taken: 0:00:14.289973\n",
      "Epoch: 90 | Train Loss: 0.11 |  Test Loss: 0.883 | Train acc: 96.124 | Test acc: 78.95 | Time taken: 0:00:14.277153\n",
      "Epoch: 91 | Train Loss: 0.116 |  Test Loss: 0.79 | Train acc: 95.846 | Test acc: 79.83 | Time taken: 0:00:14.211367\n",
      "Epoch: 92 | Train Loss: 0.117 |  Test Loss: 0.851 | Train acc: 95.738 | Test acc: 79.55 | Time taken: 0:00:14.266622\n",
      "Epoch: 93 | Train Loss: 0.107 |  Test Loss: 0.821 | Train acc: 96.166 | Test acc: 80.24 | Time taken: 0:00:14.326723\n",
      "Epoch: 94 | Train Loss: 0.105 |  Test Loss: 0.835 | Train acc: 96.368 | Test acc: 79.54 | Time taken: 0:00:14.180386\n",
      "Epoch: 95 | Train Loss: 0.108 |  Test Loss: 0.888 | Train acc: 96.04 | Test acc: 79.52 | Time taken: 0:00:14.282861\n",
      "Epoch: 96 | Train Loss: 0.11 |  Test Loss: 0.782 | Train acc: 96.11 | Test acc: 80.52 | Time taken: 0:00:14.312707\n",
      "Epoch: 97 | Train Loss: 0.108 |  Test Loss: 0.778 | Train acc: 96.17 | Test acc: 81.2 | Time taken: 0:00:14.354516\n",
      "Epoch: 98 | Train Loss: 0.101 |  Test Loss: 0.769 | Train acc: 96.362 | Test acc: 80.37 | Time taken: 0:00:14.329219\n",
      "Epoch: 99 | Train Loss: 0.097 |  Test Loss: 0.796 | Train acc: 96.552 | Test acc: 80.57 | Time taken: 0:00:14.364549\n",
      "Epoch: 100 | Train Loss: 0.098 |  Test Loss: 0.835 | Train acc: 96.546 | Test acc: 79.89 | Time taken: 0:00:14.294074\n",
      "Epoch: 1 | Train Loss: 26.921 |  Test Loss: 2.509 | Train acc: 13.004 | Test acc: 18.97 | Time taken: 0:00:14.288685\n",
      "Epoch: 2 | Train Loss: 2.273 |  Test Loss: 2.05 | Train acc: 20.41 | Test acc: 24.35 | Time taken: 0:00:14.288365\n",
      "Epoch: 3 | Train Loss: 2.065 |  Test Loss: 1.961 | Train acc: 24.184 | Test acc: 28.25 | Time taken: 0:00:14.272575\n",
      "Epoch: 4 | Train Loss: 1.965 |  Test Loss: 1.858 | Train acc: 28.752 | Test acc: 33.64 | Time taken: 0:00:14.243175\n",
      "Epoch: 5 | Train Loss: 1.867 |  Test Loss: 1.753 | Train acc: 33.112 | Test acc: 37.59 | Time taken: 0:00:14.240185\n",
      "Epoch: 6 | Train Loss: 1.74 |  Test Loss: 1.614 | Train acc: 36.778 | Test acc: 40.92 | Time taken: 0:00:14.179528\n",
      "Epoch: 7 | Train Loss: 1.641 |  Test Loss: 1.534 | Train acc: 39.894 | Test acc: 43.67 | Time taken: 0:00:14.257341\n",
      "Epoch: 8 | Train Loss: 1.556 |  Test Loss: 1.463 | Train acc: 42.85 | Test acc: 46.53 | Time taken: 0:00:14.272330\n",
      "Epoch: 9 | Train Loss: 1.493 |  Test Loss: 1.409 | Train acc: 45.8 | Test acc: 49.02 | Time taken: 0:00:14.204493\n",
      "Epoch: 10 | Train Loss: 1.433 |  Test Loss: 1.342 | Train acc: 48.07 | Test acc: 50.75 | Time taken: 0:00:14.228470\n",
      "Epoch: 11 | Train Loss: 1.383 |  Test Loss: 1.281 | Train acc: 49.97 | Test acc: 52.91 | Time taken: 0:00:14.264468\n",
      "Epoch: 12 | Train Loss: 1.314 |  Test Loss: 1.296 | Train acc: 52.458 | Test acc: 53.35 | Time taken: 0:00:14.787299\n",
      "Epoch: 13 | Train Loss: 1.263 |  Test Loss: 1.218 | Train acc: 54.402 | Test acc: 55.97 | Time taken: 0:00:14.806191\n",
      "Epoch: 14 | Train Loss: 1.232 |  Test Loss: 1.173 | Train acc: 56.13 | Test acc: 58.01 | Time taken: 0:00:14.224982\n",
      "Epoch: 15 | Train Loss: 1.176 |  Test Loss: 1.127 | Train acc: 57.892 | Test acc: 59.57 | Time taken: 0:00:14.243958\n",
      "Epoch: 16 | Train Loss: 1.127 |  Test Loss: 1.165 | Train acc: 59.894 | Test acc: 58.45 | Time taken: 0:00:14.165434\n",
      "Epoch: 17 | Train Loss: 1.088 |  Test Loss: 1.059 | Train acc: 61.214 | Test acc: 62.03 | Time taken: 0:00:14.223553\n",
      "Epoch: 18 | Train Loss: 1.053 |  Test Loss: 1.008 | Train acc: 62.614 | Test acc: 63.82 | Time taken: 0:00:14.183577\n",
      "Epoch: 19 | Train Loss: 1.009 |  Test Loss: 0.956 | Train acc: 64.21 | Test acc: 66.12 | Time taken: 0:00:14.121699\n",
      "Epoch: 20 | Train Loss: 0.981 |  Test Loss: 0.972 | Train acc: 65.184 | Test acc: 65.45 | Time taken: 0:00:14.501291\n",
      "Epoch: 21 | Train Loss: 0.953 |  Test Loss: 0.966 | Train acc: 66.174 | Test acc: 65.47 | Time taken: 0:00:14.562098\n",
      "Epoch: 22 | Train Loss: 0.922 |  Test Loss: 0.909 | Train acc: 67.524 | Test acc: 67.99 | Time taken: 0:00:15.698445\n",
      "Epoch: 23 | Train Loss: 0.899 |  Test Loss: 0.925 | Train acc: 68.238 | Test acc: 66.92 | Time taken: 0:00:10.351255\n",
      "Epoch: 24 | Train Loss: 0.866 |  Test Loss: 0.903 | Train acc: 69.386 | Test acc: 68.1 | Time taken: 0:00:10.174984\n",
      "Epoch: 25 | Train Loss: 0.857 |  Test Loss: 0.858 | Train acc: 69.884 | Test acc: 69.57 | Time taken: 0:00:10.092954\n",
      "Epoch: 26 | Train Loss: 0.824 |  Test Loss: 0.813 | Train acc: 71.06 | Test acc: 71.18 | Time taken: 0:00:09.899704\n",
      "Epoch: 27 | Train Loss: 0.792 |  Test Loss: 0.814 | Train acc: 72.346 | Test acc: 71.22 | Time taken: 0:00:10.101516\n",
      "Epoch: 28 | Train Loss: 0.77 |  Test Loss: 0.792 | Train acc: 73.03 | Test acc: 72.77 | Time taken: 0:00:10.172525\n",
      "Epoch: 29 | Train Loss: 0.743 |  Test Loss: 0.816 | Train acc: 74.024 | Test acc: 71.22 | Time taken: 0:00:10.021586\n",
      "Epoch: 30 | Train Loss: 0.727 |  Test Loss: 0.8 | Train acc: 74.414 | Test acc: 72.06 | Time taken: 0:00:09.761781\n",
      "Epoch: 31 | Train Loss: 0.707 |  Test Loss: 0.78 | Train acc: 75.294 | Test acc: 72.56 | Time taken: 0:00:10.026850\n",
      "Epoch: 32 | Train Loss: 0.687 |  Test Loss: 0.74 | Train acc: 75.814 | Test acc: 74.3 | Time taken: 0:00:10.077520\n",
      "Epoch: 33 | Train Loss: 0.67 |  Test Loss: 0.762 | Train acc: 76.336 | Test acc: 73.53 | Time taken: 0:00:09.763928\n",
      "Epoch: 34 | Train Loss: 0.653 |  Test Loss: 0.721 | Train acc: 77.034 | Test acc: 75.03 | Time taken: 0:00:09.948329\n",
      "Epoch: 35 | Train Loss: 0.63 |  Test Loss: 0.831 | Train acc: 77.98 | Test acc: 72.34 | Time taken: 0:00:09.847774\n",
      "Epoch: 36 | Train Loss: 0.63 |  Test Loss: 0.756 | Train acc: 77.656 | Test acc: 73.99 | Time taken: 0:00:09.920928\n",
      "Epoch: 37 | Train Loss: 0.61 |  Test Loss: 0.719 | Train acc: 78.578 | Test acc: 75.02 | Time taken: 0:00:10.068427\n",
      "Epoch: 38 | Train Loss: 0.588 |  Test Loss: 0.725 | Train acc: 79.474 | Test acc: 75.14 | Time taken: 0:00:09.798533\n",
      "Epoch: 39 | Train Loss: 0.569 |  Test Loss: 0.716 | Train acc: 79.844 | Test acc: 75.4 | Time taken: 0:00:10.011980\n",
      "Epoch: 40 | Train Loss: 0.564 |  Test Loss: 0.758 | Train acc: 79.96 | Test acc: 74.91 | Time taken: 0:00:10.013229\n",
      "Epoch: 41 | Train Loss: 0.541 |  Test Loss: 0.753 | Train acc: 80.826 | Test acc: 75.28 | Time taken: 0:00:09.988611\n",
      "Epoch: 42 | Train Loss: 0.545 |  Test Loss: 0.734 | Train acc: 80.934 | Test acc: 75.48 | Time taken: 0:00:10.062342\n",
      "Epoch: 43 | Train Loss: 0.519 |  Test Loss: 0.721 | Train acc: 81.644 | Test acc: 75.8 | Time taken: 0:00:10.213068\n",
      "Epoch: 44 | Train Loss: 0.5 |  Test Loss: 0.678 | Train acc: 82.384 | Test acc: 76.34 | Time taken: 0:00:10.211959\n",
      "Epoch: 45 | Train Loss: 0.486 |  Test Loss: 0.696 | Train acc: 82.884 | Test acc: 77.0 | Time taken: 0:00:10.109266\n",
      "Epoch: 46 | Train Loss: 0.476 |  Test Loss: 0.674 | Train acc: 82.958 | Test acc: 77.32 | Time taken: 0:00:10.056528\n",
      "Epoch: 47 | Train Loss: 0.467 |  Test Loss: 0.693 | Train acc: 83.29 | Test acc: 76.62 | Time taken: 0:00:10.176538\n",
      "Epoch: 48 | Train Loss: 0.457 |  Test Loss: 0.71 | Train acc: 83.774 | Test acc: 76.05 | Time taken: 0:00:09.968602\n",
      "Epoch: 49 | Train Loss: 0.456 |  Test Loss: 0.707 | Train acc: 83.654 | Test acc: 77.17 | Time taken: 0:00:10.056878\n",
      "Epoch: 50 | Train Loss: 0.44 |  Test Loss: 0.693 | Train acc: 84.51 | Test acc: 76.96 | Time taken: 0:00:09.928789\n",
      "Epoch: 51 | Train Loss: 0.423 |  Test Loss: 0.674 | Train acc: 84.79 | Test acc: 78.03 | Time taken: 0:00:10.094631\n",
      "Epoch: 52 | Train Loss: 0.409 |  Test Loss: 0.685 | Train acc: 85.402 | Test acc: 77.28 | Time taken: 0:00:09.924311\n",
      "Epoch: 53 | Train Loss: 0.409 |  Test Loss: 0.713 | Train acc: 85.426 | Test acc: 76.73 | Time taken: 0:00:09.964540\n",
      "Epoch: 54 | Train Loss: 0.399 |  Test Loss: 0.683 | Train acc: 85.808 | Test acc: 77.33 | Time taken: 0:00:10.220558\n",
      "Epoch: 55 | Train Loss: 0.384 |  Test Loss: 0.79 | Train acc: 86.394 | Test acc: 75.78 | Time taken: 0:00:10.334514\n",
      "Epoch: 56 | Train Loss: 0.379 |  Test Loss: 0.679 | Train acc: 86.332 | Test acc: 77.62 | Time taken: 0:00:10.014585\n",
      "Epoch: 57 | Train Loss: 0.37 |  Test Loss: 0.701 | Train acc: 86.624 | Test acc: 77.1 | Time taken: 0:00:09.812232\n",
      "Epoch: 58 | Train Loss: 0.362 |  Test Loss: 0.709 | Train acc: 87.014 | Test acc: 77.61 | Time taken: 0:00:09.927431\n",
      "Epoch: 59 | Train Loss: 0.362 |  Test Loss: 0.73 | Train acc: 87.08 | Test acc: 77.24 | Time taken: 0:00:10.117336\n",
      "Epoch: 60 | Train Loss: 0.345 |  Test Loss: 0.705 | Train acc: 87.466 | Test acc: 77.77 | Time taken: 0:00:10.015571\n",
      "Epoch: 61 | Train Loss: 0.329 |  Test Loss: 0.749 | Train acc: 88.034 | Test acc: 76.79 | Time taken: 0:00:10.198422\n",
      "Epoch: 62 | Train Loss: 0.334 |  Test Loss: 0.71 | Train acc: 87.89 | Test acc: 77.74 | Time taken: 0:00:10.032824\n",
      "Epoch: 63 | Train Loss: 0.318 |  Test Loss: 0.714 | Train acc: 88.424 | Test acc: 78.03 | Time taken: 0:00:09.898077\n",
      "Epoch: 64 | Train Loss: 0.312 |  Test Loss: 0.762 | Train acc: 88.772 | Test acc: 77.18 | Time taken: 0:00:09.911878\n",
      "Epoch: 65 | Train Loss: 0.314 |  Test Loss: 0.713 | Train acc: 88.508 | Test acc: 77.68 | Time taken: 0:00:09.943394\n",
      "Epoch: 66 | Train Loss: 0.314 |  Test Loss: 0.715 | Train acc: 88.642 | Test acc: 77.58 | Time taken: 0:00:10.083223\n",
      "Epoch: 67 | Train Loss: 0.293 |  Test Loss: 0.761 | Train acc: 89.368 | Test acc: 77.56 | Time taken: 0:00:10.359495\n",
      "Epoch: 68 | Train Loss: 0.289 |  Test Loss: 0.786 | Train acc: 89.572 | Test acc: 77.45 | Time taken: 0:00:10.146332\n",
      "Epoch: 69 | Train Loss: 0.288 |  Test Loss: 0.707 | Train acc: 89.606 | Test acc: 78.23 | Time taken: 0:00:10.017461\n",
      "Epoch: 70 | Train Loss: 0.281 |  Test Loss: 0.766 | Train acc: 89.858 | Test acc: 78.03 | Time taken: 0:00:10.315166\n",
      "Epoch: 71 | Train Loss: 0.276 |  Test Loss: 0.752 | Train acc: 89.99 | Test acc: 77.94 | Time taken: 0:00:09.818375\n",
      "Epoch: 72 | Train Loss: 0.281 |  Test Loss: 0.767 | Train acc: 89.814 | Test acc: 78.09 | Time taken: 0:00:09.957565\n",
      "Epoch: 73 | Train Loss: 0.266 |  Test Loss: 0.749 | Train acc: 90.398 | Test acc: 78.53 | Time taken: 0:00:10.123516\n",
      "Epoch: 74 | Train Loss: 0.265 |  Test Loss: 0.739 | Train acc: 90.328 | Test acc: 78.55 | Time taken: 0:00:10.170656\n",
      "Epoch: 75 | Train Loss: 0.254 |  Test Loss: 0.743 | Train acc: 90.746 | Test acc: 77.97 | Time taken: 0:00:10.784863\n",
      "Epoch: 76 | Train Loss: 0.246 |  Test Loss: 0.791 | Train acc: 91.228 | Test acc: 77.12 | Time taken: 0:00:10.665170\n",
      "Epoch: 77 | Train Loss: 0.258 |  Test Loss: 0.756 | Train acc: 90.668 | Test acc: 77.45 | Time taken: 0:00:10.459578\n",
      "Epoch: 78 | Train Loss: 0.241 |  Test Loss: 0.775 | Train acc: 91.32 | Test acc: 78.61 | Time taken: 0:00:10.303756\n",
      "Epoch: 79 | Train Loss: 0.241 |  Test Loss: 0.819 | Train acc: 91.436 | Test acc: 77.67 | Time taken: 0:00:10.292712\n",
      "Epoch: 80 | Train Loss: 0.235 |  Test Loss: 0.769 | Train acc: 91.576 | Test acc: 77.79 | Time taken: 0:00:10.085317\n",
      "Epoch: 81 | Train Loss: 0.231 |  Test Loss: 0.802 | Train acc: 91.648 | Test acc: 77.92 | Time taken: 0:00:10.213581\n",
      "Epoch: 82 | Train Loss: 0.223 |  Test Loss: 0.769 | Train acc: 92.042 | Test acc: 78.23 | Time taken: 0:00:10.454605\n",
      "Epoch: 83 | Train Loss: 0.225 |  Test Loss: 0.864 | Train acc: 91.816 | Test acc: 77.32 | Time taken: 0:00:10.120741\n",
      "Epoch: 84 | Train Loss: 0.223 |  Test Loss: 0.802 | Train acc: 91.96 | Test acc: 78.61 | Time taken: 0:00:10.226210\n",
      "Epoch: 85 | Train Loss: 0.214 |  Test Loss: 0.87 | Train acc: 92.276 | Test acc: 78.06 | Time taken: 0:00:10.258637\n",
      "Epoch: 86 | Train Loss: 0.215 |  Test Loss: 0.787 | Train acc: 92.208 | Test acc: 78.52 | Time taken: 0:00:09.937908\n",
      "Epoch: 87 | Train Loss: 0.212 |  Test Loss: 0.803 | Train acc: 92.326 | Test acc: 78.23 | Time taken: 0:00:10.010550\n",
      "Epoch: 88 | Train Loss: 0.214 |  Test Loss: 0.805 | Train acc: 92.17 | Test acc: 77.77 | Time taken: 0:00:09.924648\n",
      "Epoch: 89 | Train Loss: 0.216 |  Test Loss: 0.821 | Train acc: 92.274 | Test acc: 77.9 | Time taken: 0:00:09.901087\n",
      "Epoch: 90 | Train Loss: 0.208 |  Test Loss: 0.892 | Train acc: 92.678 | Test acc: 76.17 | Time taken: 0:00:10.192919\n",
      "Epoch: 91 | Train Loss: 0.201 |  Test Loss: 0.881 | Train acc: 92.824 | Test acc: 77.3 | Time taken: 0:00:10.223144\n",
      "Epoch: 92 | Train Loss: 0.202 |  Test Loss: 0.84 | Train acc: 92.666 | Test acc: 78.35 | Time taken: 0:00:10.063206\n",
      "Epoch: 93 | Train Loss: 0.194 |  Test Loss: 0.861 | Train acc: 93.052 | Test acc: 78.44 | Time taken: 0:00:10.145136\n",
      "Epoch: 94 | Train Loss: 0.195 |  Test Loss: 0.832 | Train acc: 93.004 | Test acc: 78.26 | Time taken: 0:00:10.361802\n",
      "Epoch: 95 | Train Loss: 0.208 |  Test Loss: 0.816 | Train acc: 92.548 | Test acc: 78.06 | Time taken: 0:00:10.313167\n",
      "Epoch: 96 | Train Loss: 0.194 |  Test Loss: 0.829 | Train acc: 92.906 | Test acc: 78.4 | Time taken: 0:00:10.491723\n",
      "Epoch: 97 | Train Loss: 0.195 |  Test Loss: 0.824 | Train acc: 93.036 | Test acc: 78.59 | Time taken: 0:00:10.608638\n",
      "Epoch: 98 | Train Loss: 0.189 |  Test Loss: 0.857 | Train acc: 93.262 | Test acc: 78.51 | Time taken: 0:00:10.401174\n",
      "Epoch: 99 | Train Loss: 0.188 |  Test Loss: 0.891 | Train acc: 93.23 | Test acc: 77.84 | Time taken: 0:00:10.348692\n",
      "Epoch: 100 | Train Loss: 0.198 |  Test Loss: 0.83 | Train acc: 92.862 | Test acc: 77.85 | Time taken: 0:00:10.297825\n"
     ]
    }
   ],
   "source": [
    "from utils import train\n",
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "list_of_dropout_rates = [0, 0.25, 0.5]\n",
    "list_of_activation_functions = ['sigmoid', 'relu', 'leaky_relu']\n",
    "list_of_optimizers = ['SGD', 'SGD_momentum', 'Adam']\n",
    "\n",
    "for dropout_rate in list_of_dropout_rates:\n",
    "    for activation_function_type in list_of_activation_functions:\n",
    "        for optimizer_type in list_of_optimizers:\n",
    "            net = ConvNet(dropout_rate=dropout_rate, activation_function_type=activation_function_type)\n",
    "            if optimizer_type == 'Adam':\n",
    "                optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "            elif optimizer_type == 'SGD':\n",
    "                optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "            elif optimizer_type == 'SGD_momentum':\n",
    "                 optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "            train(epochs=epochs, model=net, optimizer=optimizer, \n",
    "                criterion=criterion, train_loader=train_loader, \n",
    "                test_loader=test_loader, \n",
    "                file_name='dropout_{}_actvfunc_{}_optimizer_{}'.format(\n",
    "                    dropout_rate, activation_function_type, optimizer_type))"
   ]
  },
  {
   "source": [
    "## Create the optimal model with data augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "\n",
    "## transform link - https://colab.research.google.com/drive/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll#scrollTo=yLEwF_2RzGs0\n",
    "\n",
    "## While iterating the train_loader, we will get random transformations on the fly\n",
    "## Each epoch they will be different basically\n",
    "train_transform = transforms.Compose([\n",
    "     torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "     torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "test_trainsform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_trainsform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 | Train Loss: 1.765 |  Test Loss: 1.452 | Train acc: 35.884 | Test acc: 47.88 | Time taken: 0:00:19.774976\n",
      "Epoch: 2 | Train Loss: 1.424 |  Test Loss: 1.272 | Train acc: 48.332 | Test acc: 54.21 | Time taken: 0:00:19.665445\n",
      "Epoch: 3 | Train Loss: 1.308 |  Test Loss: 1.136 | Train acc: 52.722 | Test acc: 59.44 | Time taken: 0:00:20.288205\n",
      "Epoch: 4 | Train Loss: 1.205 |  Test Loss: 1.107 | Train acc: 56.94 | Test acc: 61.03 | Time taken: 0:00:23.053602\n",
      "Epoch: 5 | Train Loss: 1.143 |  Test Loss: 1.018 | Train acc: 59.142 | Test acc: 64.15 | Time taken: 0:00:34.271989\n",
      "Epoch: 6 | Train Loss: 1.091 |  Test Loss: 0.993 | Train acc: 61.142 | Test acc: 64.37 | Time taken: 0:00:33.246393\n",
      "Epoch: 7 | Train Loss: 1.046 |  Test Loss: 0.96 | Train acc: 63.102 | Test acc: 67.13 | Time taken: 0:00:33.887815\n",
      "Epoch: 8 | Train Loss: 1.018 |  Test Loss: 0.94 | Train acc: 64.064 | Test acc: 67.64 | Time taken: 0:00:33.890766\n",
      "Epoch: 9 | Train Loss: 0.983 |  Test Loss: 0.89 | Train acc: 65.332 | Test acc: 68.83 | Time taken: 0:00:34.362409\n",
      "Epoch: 10 | Train Loss: 0.963 |  Test Loss: 0.882 | Train acc: 66.064 | Test acc: 69.1 | Time taken: 0:00:33.324628\n",
      "Epoch: 11 | Train Loss: 0.932 |  Test Loss: 0.799 | Train acc: 67.104 | Test acc: 72.21 | Time taken: 0:00:33.747604\n",
      "Epoch: 12 | Train Loss: 0.915 |  Test Loss: 0.833 | Train acc: 67.878 | Test acc: 71.07 | Time taken: 0:00:33.307101\n",
      "Epoch: 13 | Train Loss: 0.892 |  Test Loss: 0.84 | Train acc: 68.528 | Test acc: 70.62 | Time taken: 0:00:33.101815\n",
      "Epoch: 14 | Train Loss: 0.879 |  Test Loss: 0.802 | Train acc: 69.004 | Test acc: 72.06 | Time taken: 0:00:33.741001\n",
      "Epoch: 15 | Train Loss: 0.853 |  Test Loss: 0.776 | Train acc: 70.164 | Test acc: 73.37 | Time taken: 0:00:33.281612\n",
      "Epoch: 16 | Train Loss: 0.851 |  Test Loss: 0.751 | Train acc: 70.268 | Test acc: 74.05 | Time taken: 0:00:33.291715\n",
      "Epoch: 17 | Train Loss: 0.828 |  Test Loss: 0.758 | Train acc: 70.894 | Test acc: 73.85 | Time taken: 0:00:33.390255\n",
      "Epoch: 18 | Train Loss: 0.815 |  Test Loss: 0.768 | Train acc: 71.376 | Test acc: 73.78 | Time taken: 0:00:33.912045\n",
      "Epoch: 19 | Train Loss: 0.807 |  Test Loss: 0.816 | Train acc: 71.634 | Test acc: 72.29 | Time taken: 0:00:33.222234\n",
      "Epoch: 20 | Train Loss: 0.8 |  Test Loss: 0.775 | Train acc: 71.9 | Test acc: 73.38 | Time taken: 0:00:33.199770\n",
      "Epoch: 21 | Train Loss: 0.784 |  Test Loss: 0.78 | Train acc: 72.718 | Test acc: 73.6 | Time taken: 0:00:33.463425\n",
      "Epoch: 22 | Train Loss: 0.776 |  Test Loss: 0.753 | Train acc: 72.976 | Test acc: 74.33 | Time taken: 0:00:33.478635\n",
      "Epoch: 23 | Train Loss: 0.763 |  Test Loss: 0.674 | Train acc: 73.086 | Test acc: 76.73 | Time taken: 0:00:34.635224\n",
      "Epoch: 24 | Train Loss: 0.751 |  Test Loss: 0.695 | Train acc: 73.638 | Test acc: 75.94 | Time taken: 0:00:34.751777\n",
      "Epoch: 25 | Train Loss: 0.744 |  Test Loss: 0.702 | Train acc: 73.756 | Test acc: 76.44 | Time taken: 0:00:33.811795\n",
      "Epoch: 26 | Train Loss: 0.735 |  Test Loss: 0.787 | Train acc: 74.328 | Test acc: 73.26 | Time taken: 0:00:33.329190\n",
      "Epoch: 27 | Train Loss: 0.736 |  Test Loss: 0.683 | Train acc: 74.26 | Test acc: 76.76 | Time taken: 0:00:33.164586\n",
      "Epoch: 28 | Train Loss: 0.72 |  Test Loss: 0.691 | Train acc: 74.892 | Test acc: 76.75 | Time taken: 0:00:33.335574\n",
      "Epoch: 29 | Train Loss: 0.714 |  Test Loss: 0.674 | Train acc: 75.196 | Test acc: 77.05 | Time taken: 0:00:33.691016\n",
      "Epoch: 30 | Train Loss: 0.709 |  Test Loss: 0.665 | Train acc: 75.27 | Test acc: 77.51 | Time taken: 0:00:33.022883\n",
      "Epoch: 31 | Train Loss: 0.697 |  Test Loss: 0.665 | Train acc: 75.528 | Test acc: 77.11 | Time taken: 0:00:33.196414\n",
      "Epoch: 32 | Train Loss: 0.692 |  Test Loss: 0.645 | Train acc: 75.838 | Test acc: 77.72 | Time taken: 0:00:33.743530\n",
      "Epoch: 33 | Train Loss: 0.681 |  Test Loss: 0.657 | Train acc: 76.15 | Test acc: 77.41 | Time taken: 0:00:33.231260\n",
      "Epoch: 34 | Train Loss: 0.677 |  Test Loss: 0.617 | Train acc: 76.174 | Test acc: 78.73 | Time taken: 0:00:33.349897\n",
      "Epoch: 35 | Train Loss: 0.674 |  Test Loss: 0.753 | Train acc: 76.65 | Test acc: 74.39 | Time taken: 0:00:33.211216\n",
      "Epoch: 36 | Train Loss: 0.666 |  Test Loss: 0.648 | Train acc: 76.714 | Test acc: 77.86 | Time taken: 0:00:33.639693\n",
      "Epoch: 37 | Train Loss: 0.666 |  Test Loss: 0.631 | Train acc: 76.72 | Test acc: 78.54 | Time taken: 0:00:33.323099\n",
      "Epoch: 38 | Train Loss: 0.661 |  Test Loss: 0.602 | Train acc: 76.73 | Test acc: 79.24 | Time taken: 0:00:33.217356\n",
      "Epoch: 39 | Train Loss: 0.654 |  Test Loss: 0.608 | Train acc: 77.138 | Test acc: 79.23 | Time taken: 0:00:33.472171\n",
      "Epoch: 40 | Train Loss: 0.649 |  Test Loss: 0.634 | Train acc: 77.368 | Test acc: 78.02 | Time taken: 0:00:33.340078\n",
      "Epoch: 41 | Train Loss: 0.654 |  Test Loss: 0.595 | Train acc: 77.05 | Test acc: 79.31 | Time taken: 0:00:33.217776\n",
      "Epoch: 42 | Train Loss: 0.64 |  Test Loss: 0.627 | Train acc: 77.706 | Test acc: 78.65 | Time taken: 0:00:33.201875\n",
      "Epoch: 43 | Train Loss: 0.634 |  Test Loss: 0.588 | Train acc: 77.854 | Test acc: 79.72 | Time taken: 0:00:33.758057\n",
      "Epoch: 44 | Train Loss: 0.624 |  Test Loss: 0.579 | Train acc: 78.0 | Test acc: 79.97 | Time taken: 0:00:33.325874\n",
      "Epoch: 45 | Train Loss: 0.619 |  Test Loss: 0.619 | Train acc: 78.312 | Test acc: 78.55 | Time taken: 0:00:33.389488\n",
      "Epoch: 46 | Train Loss: 0.615 |  Test Loss: 0.577 | Train acc: 78.498 | Test acc: 80.31 | Time taken: 0:00:33.741904\n",
      "Epoch: 47 | Train Loss: 0.623 |  Test Loss: 0.599 | Train acc: 78.096 | Test acc: 79.66 | Time taken: 0:00:33.648791\n",
      "Epoch: 48 | Train Loss: 0.61 |  Test Loss: 0.583 | Train acc: 78.812 | Test acc: 80.08 | Time taken: 0:00:33.395504\n",
      "Epoch: 49 | Train Loss: 0.61 |  Test Loss: 0.569 | Train acc: 78.728 | Test acc: 80.87 | Time taken: 0:00:33.415771\n",
      "Epoch: 50 | Train Loss: 0.603 |  Test Loss: 0.596 | Train acc: 79.028 | Test acc: 79.7 | Time taken: 0:00:33.991390\n",
      "Epoch: 51 | Train Loss: 0.604 |  Test Loss: 0.586 | Train acc: 78.844 | Test acc: 80.3 | Time taken: 0:00:33.723596\n",
      "Epoch: 52 | Train Loss: 0.601 |  Test Loss: 0.601 | Train acc: 78.84 | Test acc: 79.31 | Time taken: 0:00:33.432724\n",
      "Epoch: 53 | Train Loss: 0.594 |  Test Loss: 0.629 | Train acc: 79.126 | Test acc: 79.25 | Time taken: 0:00:33.553403\n",
      "Epoch: 54 | Train Loss: 0.588 |  Test Loss: 0.565 | Train acc: 79.326 | Test acc: 80.94 | Time taken: 0:00:33.796679\n",
      "Epoch: 55 | Train Loss: 0.581 |  Test Loss: 0.572 | Train acc: 79.782 | Test acc: 80.95 | Time taken: 0:00:33.519549\n",
      "Epoch: 56 | Train Loss: 0.58 |  Test Loss: 0.559 | Train acc: 79.758 | Test acc: 81.22 | Time taken: 0:00:33.329263\n",
      "Epoch: 57 | Train Loss: 0.577 |  Test Loss: 0.612 | Train acc: 79.778 | Test acc: 79.79 | Time taken: 0:00:34.064235\n",
      "Epoch: 58 | Train Loss: 0.582 |  Test Loss: 0.648 | Train acc: 79.528 | Test acc: 78.78 | Time taken: 0:00:33.599459\n",
      "Epoch: 59 | Train Loss: 0.578 |  Test Loss: 0.617 | Train acc: 79.75 | Test acc: 78.95 | Time taken: 0:00:33.293100\n",
      "Epoch: 60 | Train Loss: 0.579 |  Test Loss: 0.547 | Train acc: 79.616 | Test acc: 81.11 | Time taken: 0:00:33.382692\n",
      "Epoch: 61 | Train Loss: 0.569 |  Test Loss: 0.584 | Train acc: 79.946 | Test acc: 80.26 | Time taken: 0:00:33.938361\n",
      "Epoch: 62 | Train Loss: 0.563 |  Test Loss: 0.529 | Train acc: 80.352 | Test acc: 81.74 | Time taken: 0:00:33.562013\n",
      "Epoch: 63 | Train Loss: 0.559 |  Test Loss: 0.552 | Train acc: 80.552 | Test acc: 81.73 | Time taken: 0:00:33.400228\n",
      "Epoch: 64 | Train Loss: 0.558 |  Test Loss: 0.612 | Train acc: 80.69 | Test acc: 79.27 | Time taken: 0:00:33.493302\n",
      "Epoch: 65 | Train Loss: 0.553 |  Test Loss: 0.608 | Train acc: 80.658 | Test acc: 79.64 | Time taken: 0:00:33.632556\n",
      "Epoch: 66 | Train Loss: 0.546 |  Test Loss: 0.549 | Train acc: 80.808 | Test acc: 81.23 | Time taken: 0:00:33.378253\n",
      "Epoch: 67 | Train Loss: 0.548 |  Test Loss: 0.577 | Train acc: 80.73 | Test acc: 80.6 | Time taken: 0:00:33.475356\n",
      "Epoch: 68 | Train Loss: 0.545 |  Test Loss: 0.546 | Train acc: 81.028 | Test acc: 81.29 | Time taken: 0:00:33.918326\n",
      "Epoch: 69 | Train Loss: 0.554 |  Test Loss: 0.544 | Train acc: 80.592 | Test acc: 81.52 | Time taken: 0:00:33.420894\n",
      "Epoch: 70 | Train Loss: 0.543 |  Test Loss: 0.532 | Train acc: 80.832 | Test acc: 81.88 | Time taken: 0:00:33.496349\n",
      "Epoch: 71 | Train Loss: 0.542 |  Test Loss: 0.519 | Train acc: 81.096 | Test acc: 82.25 | Time taken: 0:00:33.547803\n",
      "Epoch: 72 | Train Loss: 0.533 |  Test Loss: 0.545 | Train acc: 81.338 | Test acc: 81.65 | Time taken: 0:00:33.444312\n",
      "Epoch: 73 | Train Loss: 0.533 |  Test Loss: 0.531 | Train acc: 81.15 | Test acc: 81.99 | Time taken: 0:00:33.279047\n",
      "Epoch: 74 | Train Loss: 0.531 |  Test Loss: 0.592 | Train acc: 81.394 | Test acc: 80.26 | Time taken: 0:00:33.580036\n",
      "Epoch: 75 | Train Loss: 0.528 |  Test Loss: 0.516 | Train acc: 81.42 | Test acc: 82.34 | Time taken: 0:00:33.960735\n",
      "Epoch: 76 | Train Loss: 0.528 |  Test Loss: 0.534 | Train acc: 81.452 | Test acc: 81.75 | Time taken: 0:00:33.519181\n",
      "Epoch: 77 | Train Loss: 0.527 |  Test Loss: 0.553 | Train acc: 81.53 | Test acc: 81.54 | Time taken: 0:00:33.492972\n",
      "Epoch: 78 | Train Loss: 0.533 |  Test Loss: 0.511 | Train acc: 81.372 | Test acc: 82.53 | Time taken: 0:00:33.613439\n",
      "Epoch: 79 | Train Loss: 0.514 |  Test Loss: 0.626 | Train acc: 81.816 | Test acc: 79.23 | Time taken: 0:00:33.605906\n",
      "Epoch: 80 | Train Loss: 0.512 |  Test Loss: 0.509 | Train acc: 81.894 | Test acc: 82.51 | Time taken: 0:00:33.406178\n",
      "Epoch: 81 | Train Loss: 0.509 |  Test Loss: 0.603 | Train acc: 82.084 | Test acc: 79.78 | Time taken: 0:00:33.245030\n",
      "Epoch: 82 | Train Loss: 0.515 |  Test Loss: 0.577 | Train acc: 82.08 | Test acc: 80.65 | Time taken: 0:00:33.700811\n",
      "Epoch: 83 | Train Loss: 0.517 |  Test Loss: 0.51 | Train acc: 81.902 | Test acc: 82.59 | Time taken: 0:00:33.325185\n",
      "Epoch: 84 | Train Loss: 0.507 |  Test Loss: 0.569 | Train acc: 82.03 | Test acc: 81.34 | Time taken: 0:00:33.282422\n",
      "Epoch: 85 | Train Loss: 0.502 |  Test Loss: 0.545 | Train acc: 82.354 | Test acc: 81.76 | Time taken: 0:00:33.306422\n",
      "Epoch: 86 | Train Loss: 0.509 |  Test Loss: 0.552 | Train acc: 82.176 | Test acc: 81.4 | Time taken: 0:00:33.679845\n",
      "Epoch: 87 | Train Loss: 0.502 |  Test Loss: 0.506 | Train acc: 82.396 | Test acc: 82.89 | Time taken: 0:00:33.248943\n",
      "Epoch: 88 | Train Loss: 0.494 |  Test Loss: 0.521 | Train acc: 82.75 | Test acc: 82.62 | Time taken: 0:00:33.285569\n",
      "Epoch: 89 | Train Loss: 0.495 |  Test Loss: 0.499 | Train acc: 82.57 | Test acc: 82.82 | Time taken: 0:00:33.668497\n",
      "Epoch: 90 | Train Loss: 0.491 |  Test Loss: 0.531 | Train acc: 82.698 | Test acc: 81.87 | Time taken: 0:00:33.499596\n",
      "Epoch: 91 | Train Loss: 0.487 |  Test Loss: 0.501 | Train acc: 82.932 | Test acc: 83.27 | Time taken: 0:00:33.388367\n",
      "Epoch: 92 | Train Loss: 0.49 |  Test Loss: 0.514 | Train acc: 82.708 | Test acc: 82.92 | Time taken: 0:00:33.427627\n",
      "Epoch: 93 | Train Loss: 0.493 |  Test Loss: 0.559 | Train acc: 82.68 | Test acc: 81.48 | Time taken: 0:00:33.755832\n",
      "Epoch: 94 | Train Loss: 0.482 |  Test Loss: 0.5 | Train acc: 82.898 | Test acc: 83.26 | Time taken: 0:00:33.313183\n",
      "Epoch: 95 | Train Loss: 0.49 |  Test Loss: 0.518 | Train acc: 82.852 | Test acc: 82.75 | Time taken: 0:00:33.411242\n",
      "Epoch: 96 | Train Loss: 0.488 |  Test Loss: 0.54 | Train acc: 82.906 | Test acc: 81.58 | Time taken: 0:00:33.449220\n",
      "Epoch: 97 | Train Loss: 0.486 |  Test Loss: 0.517 | Train acc: 82.818 | Test acc: 82.74 | Time taken: 0:00:33.776625\n",
      "Epoch: 98 | Train Loss: 0.481 |  Test Loss: 0.545 | Train acc: 83.078 | Test acc: 81.97 | Time taken: 0:00:33.374971\n",
      "Epoch: 99 | Train Loss: 0.476 |  Test Loss: 0.561 | Train acc: 83.11 | Test acc: 80.85 | Time taken: 0:00:33.349890\n",
      "Epoch: 100 | Train Loss: 0.477 |  Test Loss: 0.501 | Train acc: 83.362 | Test acc: 83.07 | Time taken: 0:00:33.671537\n"
     ]
    }
   ],
   "source": [
    "from utils import train\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "## Optimal network params\n",
    "optimal_dropout = 0.5\n",
    "optimal_activation_func_type = 'leaky_relu'\n",
    "optimal_net = ConvNet(dropout_rate=optimal_dropout, activation_function_type=optimal_activation_func_type)\n",
    "optimal_optimizer_type = 'SGD_momentum'\n",
    "optimal_optimizer = optim.SGD(optimal_net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "train(epochs=epochs, model=optimal_net, optimizer=optimal_optimizer, \n",
    "                criterion=criterion, train_loader=train_loader, \n",
    "                test_loader=test_loader, \n",
    "                file_name='dropout_{}_actvfunc_{}_optimizer_{}_augmented'.format(\n",
    "                    optimal_dropout, optimal_activation_func_type, optimal_optimizer_type))"
   ]
  }
 ]
}